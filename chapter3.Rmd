# Week3 - Logistic Regression

I prepared myself for this weeks topic by completing DataCamp exercise on "Logistic Regression".

## Data Wrangling
As I did last week, for the data wrangling part of this weeks exercises I mostly used the methods learned from the DataCamp exercise. I learned about joining datasets and doing data mutations.

My source code used in the wrangling is [here](https://github.com/ittobor/IODS-project/blob/master/data/create_alc.R).  

Basically, here are the main points what is done in the code:

* Initial dataset is acquired and extracted manually from given web source.
* Two data sets are read in and combined as one, since they contain answers from same students, by joining them based on variables: `school`,`sex`,`age`,`address`,`famsize`,`Pstatus`,`Medu`,`Fedu`,`Mjob`,`Fjob`,`reason`,`nursery`,`internet`
* The columns not used in join are combined by taking rounded avarage of numerical values and by selecting the first value of not numeric values
* `alc_use` variable was generated to indicate alcohol use (avarage of daily and weekly consumption)
* `high_use` variables was generated to indicate high use of alcohol (true is `alc_use` > 2)

The dataset (`alc.csv`) that the code created can be found from [here](https://github.com/ittobor/IODS-project/blob/master/data/alc.csv).

## Data Analysis

### Step 1 - New markdown file
Step one was to create chapter3.Rmd to inject this content to the diary as a child of subscipts in index.Rmd.

### Step 2 - Combined dataset and attributes 

The combined dataset contains the data from two Portuguese schools and were originally gathered from school reports and questionnaires. The data was collected initally in two datasets, one regarding student performance in mathemathics and one regarding student performance in Portuguese language. In addition to section Data Wrangling, in which the join criteria and additionally created variables are discussed, you can find more information about the variables in [here](https://archive.ics.uci.edu/ml/datasets/Student+Performance).

```{r echo=FALSE, message=FALSE}
library(ggplot2)
library(GGally)
library(dplyr)
library(tidyr)
alc <- read.table("https://raw.githubusercontent.com/ittobor/IODS-project/master/data/alc.csv", sep=";", header=TRUE)
```
Dimensions and the column (variable) names of the combined dataset:
```{r echo=TRUE}
dim(alc)
colnames(alc)
```
Column (variable) types of the combined dataset:
```{r echo=TRUE}
glimpse(alc)
```

### Step 3 - Variables to study in relations with alcohol consumption

My hypothesis to study is how time consumption is related with alcohol consumption. The idea being that if you spend your time with activities you would not have time to consume alcohol and vice versa. My choice of variables are in sense time consuming variables: `freetime`, `goout`, `studytime` and `traveltime`.  

* `traveltime` - Home to school travel time. My intuition here is this would be a factor to decrease alcohol consumption.
* `studytime` - Weekly study time. My intuition here is this would be a factor to decrease alcohol consumption.
* `freetime` - Free time after school. My intuition here is this would be a factor to increase alcohol consumption.
* `goout` - Going out with friends. My intuition here is this would be a factor to increase alcohol consumption.

### Step 4 - Numerical and graphical exploration on chosen variables

Here I use `ggpairs`, from last week, to visualize the chosen variables together with the variable `high_use`. From the diagram we get quickly a good overview of the relations of the variables between themselves and with the variable `high_use`. By looking at the correlation coefficients we can observe that there is not much correlation between the chosen variables. We could say that `freetime` and `goout` mildly correlate positively, meaning that you would go out with friends during your freetime which makes common sense. Also that `traveltime` and `studytime` mildly correlate negatively, the same with `freetime` and `studytime`, meaning that travel time between school and home, also freetime, is not used for studying. My interpretation is that the low correlation between the chosen variables could tell that variables are not interfering with each other and be independently a factor to increase or decrease alcohol consumption. And that can be seen in favor of my hypothesis.

From the density plots we can see that there are some deviations for each of the chosen variable when comparing to high/low alcohol usage. Most distinctive difference is between `goout` and `high_use` where we could say that those who go out more have the tendency to high alcohol consumption. When comparing `freetime` and `high_use` density one could argue that when you have less free time there is less observations of high alcohol consumptions which are growing when you have more free time. Similar argument can be made when comparing `studytime` and `high_use`, where there are less high alcohol consumption when more time spent on studies. And also when comparing `traveltime` and `high_use` one could say that if you live close to school you have more time to consume alcohol. In my interpretation these are still supporting my hypothesis, but it is not so clear because the densities between low/high alcohol consumption per chosen variable are very similar: there are 1/3 high consuming versus 2/3 low consuming observations, and the values of the attiributes are dicrete and few.

```{r echo=FALSE}
alc_min <- data.frame(matrix(ncol=0,nrow=382))
alc_min$high_use <- alc$high_use
alc_min$traveltime <- alc$traveltime
alc_min$studytime <- alc$studytime
alc_min$goout <- alc$goout
alc_min$freetime <- alc$freetime

ggpairs(alc_min, 
        mapping = aes(col = high_use, alpha = 0.3, fill=high_use), 
        lower = list(combo = wrap("facethist", bins = 20))) + ggtitle("Student traveltime, studytime,\nfreetime and goout relations by alcohol consumption")
```

Looking at the box and bar plots of each chosen variable divided by alcohol we can see that `traveltime` and `freetime` are quite identically distributed both in terms of high and low alcohol consumption. When looking at the high alcohol consumption with  `freetime` it seems that the hight alcohol consumption increases more when freetime increases, whereas low alcohol consumption increases less when freetime increases.

```{r echo=FALSE, fig.show='hold', out.width='25%'}
hu_traveltime_box <- ggplot(alc_min, aes(x = high_use, y = traveltime, col = high_use))
hu_traveltime_box + geom_boxplot() + ylab("traveltime") + ggtitle("Student traveltime by alcohol consumption BOX")

hu_traveltime_his <- ggplot(alc_min, aes(x=traveltime, fill=high_use))
hu_traveltime_his + geom_bar() + coord_flip() + ggtitle("Student traveltime by alcohol consumption BAR")

hu_freetime_box <- ggplot(alc_min, aes(x = high_use, y = freetime, col = high_use))
hu_freetime_box + geom_boxplot() + ylab("freetime") + ggtitle("Student freetime by alcohol consumption BOX")

hu_freetime_his <- ggplot(alc_min, aes(x=freetime, fill=high_use))
hu_freetime_his + geom_bar() + coord_flip() + ggtitle("Student freetime by alcohol consumption BAR")
```

With `studytime` and `goout` the distributions differ more in terms of high and low alcohol consumption. When looking at the high alcohol consumption with  `studytime` it seems that the high alcohol consumption increases more when studytime decreases compared to low alcohol consumption. Also high alcohol consumption increases more when go out time with friends increases compared to low alcohol consumption.

```{r echo=FALSE, fig.show='hold', out.width='25%'}
hu_studytime_box <- ggplot(alc_min, aes(x = high_use, y = studytime, col = high_use))
hu_studytime_box + geom_boxplot() + ylab("studytime") + ggtitle("Student studytime by alcohol consumption BOX")

hu_studytime_his <- ggplot(alc_min, aes(x=studytime, fill=high_use))
hu_studytime_his + geom_bar() + coord_flip() + ggtitle("Student studytime by alcohol consumption BAR")

hu_goout_box <- ggplot(alc_min, aes(x = high_use, y = goout, col = high_use))
hu_goout_box + geom_boxplot() + ylab("goout") + ggtitle("Student go out by alcohol consumption BOX")

hu_goout_his <- ggplot(alc_min, aes(x=goout, fill=high_use))
hu_goout_his + geom_bar() + coord_flip() + ggtitle("Student go out by alcohol consumption BAR")
```

### Step 5 - Statistical exploration with logistic regression

Here we use logistic regression to statistically explore the relationship between chosen variables and the binary high/low alcohol consumption.
```{r echo=FALSE}
model <- glm(high_use ~ studytime + goout + traveltime + freetime, data = alc, family = "binomial")
summary(model)
```

From the summary we can see the distribution of deviance residuals for the individual cases used in the model. The table of coeffiecients shows the coefficients and its standard error for each variable. The coefficients tell the change in the log odds  of the outcome for a one unit increase in the predictor variable (e.g. one unit change in `goout` gives the log odds of `high_use` increase by 0.7206). From the p-values we can see that the probability of each variable NOT being relevant (so low score here is good). From the significance indicators we can tell that `studytime`, `goout` and `traveltime` are statistically significant, but `freetime` is not.

From the below odd ratios of the coefficients we can say that each of the chosen variable is positively associated with high consumption of alcohol (when we have defined `high_use` as binary, TRUE / FALSE). From the odds ratios and confidence intervals we can say that since `studytime` is below 1 values (the odds ratio and the confidence interval) it is in favor of low alcohol consumption. Both `goout` and `traveltime` is above 1 so they both are in favor of high alcohol consumption. Where as `freetime` has interval that includes value 1, meaning that it is random to which side the variable is in favor of.

```{r echo=FALSE, message=FALSE}
OR <- coef(model) %>% exp
CI <- confint(model) %>% exp
cbind(OR, CI)
```

Based on summary and odds ratios I conclude that `studytime`, `goout` and `traveltime` support my hypothesis but surprisingly `freetime` does not. And since `freetime` is not statistically significant I will drop that variable from further parts of this exercise analysis.

### Step 6 - Predicative power of the model

First we need to re-fit the model by taking out the statistically not significant `freetime` variable.

```{r echo=FALSE}
model <- glm(high_use ~ studytime + goout + traveltime, data = alc, family = "binomial")
summary(model)

probabilities <- predict(model, type = "response")
alc_min <- mutate(alc_min, probability = probabilities)
alc_min <- mutate(alc_min, prediction = probability > 0.5)
```

Then we use the model to predict probabilities for the date that was used to train the model.
Based on the probabilities we make predictions for the training data observations so that `probability > 0.5` is high alcohol consumption, otherwise low. In the first table below we can see the counts of the true values of `high_use` and of the predictions. And in the second table are the proportions of the same. From these we can compute that the model gets it (0.63874346 + 0.11780105 = 0.75654451) ~76% times correct, meaning the training error being ~24%. The model gets 91% of the true low alcohol consumption observations correct, but only ~39% of the true high alcohol consumption observations correct. 

```{r echo=FALSE}
taabla <- table(high_use = alc_min$high_use, prediction = alc_min$prediction)
taabla %>% addmargins()
taabla %>% prop.table() %>% addmargins()
```

As as performance comparison to a simple guessing strategy, with weights 2/3 to low alcohol consumption and 1/3 to high alcohol consumption, we can see that the model beats this guessing strategy. The results from the simple guessing strategy is below. Simple guessing strategy get ~59% correct from the true totals, ~70% of the true low alcohol consumption and ~32% of the true high alcohol consumption. (Note: Since guessing strategy is based on randomizer there might be slight changes on percentages written above and how many time this rmarkdown code is run after what I had written)

```{r echo=FALSE}
set.seed(1)
sampula <- sample(c(0,1), size=382, replace=TRUE, prob=c(2/3,1/3))
taabla2 <- table(high_use = alc_min$high_use, prediction = sampula)
taabla2 %>% addmargins()
taabla2 %>% prop.table() %>% addmargins()
```

Here is also graphical visualization of the actual and predicted values.

```{r echo=FALSE}
hu_prediction <- ggplot(alc_min, aes(x = probability, y = high_use, col = prediction))
hu_prediction + geom_point() + ggtitle("Actual values of high_use vs perdictions by the model")
```

### Step 7 - 10-fold cross-validation BONUS

For the 10-fold cross-validation we need to define a loss function. I use the same definition of loss function as was done in the Data Camp exercises. Here is the error-rate of the above trained model computed with the loss function.
```{r echo=FALSE}
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

loss_func(class=alc_min$high_use, prob=alc_min$probability)
```
And here is the error-rate of the trained model wih 10-fold cross-validation. As you can see the model slightly outperforms the model used in Data Camp exercise.
```{r echo=FALSE}
# K-fold cross-validation
library(boot)
cv <- cv.glm(data = alc_min, cost = loss_func, glmfit = model, K = 10)

# average number of wrong predictions in the cross validation
cv$delta[1]
```

### Step 8 - Cross-validation of performance of different logistic regression models SUPERBONUS

In this part of the exercise set I used only variables that are of numeric type (type:int). There are 14 such variables.
I use for loop to add a predictor in one-by-one fashion and do the cross-validation step to store the error in betweens.
Unfortunately my plotting skills are poor and I was not able to flip the value-labels of x-axis (was able to flip the "curve" but decided not to since it would make it more confusing), hence the errors are represented in this plot in increasing number of predictors order. 

```{r echo=FALSE}
predictor <- c("age","Medu","Fedu","traveltime","studytime","failures","famrel","freetime","goout","health" ,"absences","G1","G2","G3")
predictors_in = ""
errs <- 1:length(predictor)
x <- 1:length(predictor)
for(i in 1:length(predictor)) {
  if (i == 1) {
    predictors_in = predictor[i]
  } else {
    predictors_in = paste(predictors_in, predictor[i],sep="+")
  }
  m2 <- glm(paste("high_use ~ ", predictors_in, sep = ""), data = alc, family = "binomial")
  
  cv <- cv.glm(data = alc, cost = loss_func, glmfit = m2, K = 10)
  errs[i] <- cv$delta[1]
}
plot(x, errs, type='b', xlim = range(x))
errs
```
